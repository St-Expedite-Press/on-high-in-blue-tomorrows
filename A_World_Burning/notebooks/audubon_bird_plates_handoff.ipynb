{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Audubon Bird Plates - Handoff + Contract Assertions (Google Colab)\n\nUse this notebook as the **standard entrypoint** for any Colab work that assumes the dataset has already been scaffolded (i.e., `plates_structured/`, schemas, checksums, ledger).\n\nIt provides:\n- A read-only handoff cell that mounts Drive, resolves `DATASET_ROOT`, and exposes canonical paths\n- A read-only structure + naming contract assertion that aborts early on drift\n- Optional cleanup and exploratory inspection cells\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================================\n# HANDOFF: LOAD PROJECT CONTEXT (READ-ONLY)\n# ------------------------------------------------------------\n# Purpose:\n#   - Mount Drive\n#   - Resolve dataset root\n#   - Expose canonical paths\n#   - Perform LIGHT sanity checks only\n#\n# This cell MUST:\n#   - Not write files\n#   - Not validate schemas deeply\n#   - Not compute checksums\n# ============================================================\n\nfrom google.colab import drive\nfrom pathlib import Path\nimport json\n\n# -----------------------------\n# Mount Drive\n# -----------------------------\n\ndrive.mount(\"/content/drive\", force_remount=False)\n\n# -----------------------------\n# Resolve project + dataset\n# -----------------------------\n\nPROJECT_ROOT = Path(\"/content/drive/MyDrive/burning-world-series\")\nassert PROJECT_ROOT.exists(), \"Project root missing\"\n\nDATASET_ROOT = next(\n    p for p in PROJECT_ROOT.iterdir()\n    if p.is_dir() and p.name.startswith(\"audubon-bird-plates\")\n)\n\n# -----------------------------\n# Canonical paths (AUTHORITATIVE)\n# -----------------------------\n\nPLATES_ORIGINAL   = DATASET_ROOT / \"plates\"\nPLATES_STRUCTURED = DATASET_ROOT / \"plates_structured\"\nSCHEMA_DIR        = DATASET_ROOT / \"schemas\"\nLEDGER_DIR        = DATASET_ROOT / \"ledger\"\nDATA_JSON         = DATASET_ROOT / \"data.json\"\nREADME_MD         = DATASET_ROOT / \"README.md\"\n\n# -----------------------------\n# Lightweight sanity checks\n# -----------------------------\n\nassert PLATES_STRUCTURED.exists(), \"plates_structured missing\"\nassert SCHEMA_DIR.exists(), \"schemas missing\"\nassert LEDGER_DIR.exists(), \"ledger missing\"\nassert DATA_JSON.exists(), \"data.json missing\"\n\nplate_dirs = [p for p in PLATES_STRUCTURED.iterdir() if p.is_dir()]\nassert len(plate_dirs) == 435, \"Unexpected plate count\"\n\n# -----------------------------\n# Convenience handles\n# -----------------------------\n\ndef get_plate_dir(plate_number: int) -> Path:\n    return PLATES_STRUCTURED / f\"plate-{str(plate_number).zfill(3)}\"\n\ndef load_plate_manifest(plate_number: int) -> dict:\n    plate_dir = get_plate_dir(plate_number)\n    return json.loads((plate_dir / \"manifest.json\").read_text())\n\n# -----------------------------\n# Confirmation\n# -----------------------------\n\nprint(\"Project loaded successfully.\")\nprint(f\"Dataset root      : {DATASET_ROOT.name}\")\nprint(f\"Structured plates : {len(plate_dirs)}\")\nprint(\"Ready for runs, embeddings, or analysis.\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================================\n# STRUCTURE & NAMING CONTRACT ASSERTION (READ-ONLY)\n# ------------------------------------------------------------\n# Purpose:\n#   - Re-assert filesystem law\n#   - Confirm naming conventions\n#   - Abort early if drift has occurred\n#\n# This cell:\n#   - Reads only\n#   - Raises on any deviation\n# ============================================================\n\nimport json\nimport re\n\nprint(\"\\n==============================\")\nprint(\"STRUCTURE & NAMING ASSERTION\")\nprint(\"==============================\\n\")\n\n# ------------------------------------------------------------\n# 1. Canonical roots must exist\n# ------------------------------------------------------------\n\nassert DATASET_ROOT.exists(), \"DATASET_ROOT missing\"\nassert PLATES_STRUCTURED.exists(), \"plates_structured missing\"\nassert SCHEMA_DIR.exists(), \"schemas missing\"\nassert LEDGER_DIR.exists(), \"ledger missing\"\n\nprint(\"[1] Canonical roots present (OK)\")\n\n# ------------------------------------------------------------\n# 2. Plate directory naming law\n# ------------------------------------------------------------\n\nplate_dirs = sorted(p for p in PLATES_STRUCTURED.iterdir() if p.is_dir())\nassert len(plate_dirs) == 435, \"Plate count must be exactly 435\"\n\nplate_name_re = re.compile(r\"^plate-\\d{3}$\")\nbad_names = [p.name for p in plate_dirs if not plate_name_re.match(p.name)]\nassert not bad_names, f\"Invalid plate directory names: {bad_names[:5]}\"\n\nprint(\"[2] Plate directory naming OK (OK)\")\n\n# ------------------------------------------------------------\n# 3. Per-plate internal structure law\n# ------------------------------------------------------------\n\nrequired_subdirs = {\"source\", \"runs\", \"viz\", \"cache\"}\nviolations = []\n\nfor plate_dir in plate_dirs:\n    contents = {p.name for p in plate_dir.iterdir()}\n\n    missing = required_subdirs - contents\n    if missing:\n        violations.append(f\"{plate_dir.name}: missing {missing}\")\n\n    # source/ must contain exactly one file\n    source_dir = plate_dir / \"source\"\n    if source_dir.exists():\n        files = [p for p in source_dir.iterdir() if p.is_file()]\n        if len(files) != 1:\n            violations.append(f\"{plate_dir.name}: source/ has {len(files)} files\")\n\n    # required files\n    for fname in (\"manifest.json\", \"source.sha256\"):\n        if not (plate_dir / fname).exists():\n            violations.append(f\"{plate_dir.name}: missing {fname}\")\n\nassert not violations, f\"Plate structure violations:\\n{violations[:5]}\"\n\nprint(\"[3] Plate internal structure OK (OK)\")\n\n# ------------------------------------------------------------\n# 4. Manifest <-> filesystem consistency\n# ------------------------------------------------------------\n\nfor plate_dir in plate_dirs:\n    manifest = json.loads((plate_dir / \"manifest.json\").read_text())\n\n    # plate_id consistency\n    assert manifest[\"plate_id\"] == plate_dir.name, f\"{plate_dir.name}: plate_id mismatch\"\n\n    # source image path consistency\n    src = plate_dir / manifest[\"source_image\"]\n    assert src.exists(), f\"{plate_dir.name}: source_image missing\"\n\nprint(\"[4] Manifest <-> filesystem consistency OK (OK)\")\n\n# ------------------------------------------------------------\n# 5. Run directory naming law (if present)\n# ------------------------------------------------------------\n\nrun_re = re.compile(r\"^run-\\d{8}-\\d{6}-[a-f0-9]{8}$\")\n\nfor plate_dir in plate_dirs:\n    runs_dir = plate_dir / \"runs\"\n    if not runs_dir.exists():\n        continue\n\n    for run in runs_dir.iterdir():\n        if not run.is_dir():\n            continue\n        assert run_re.match(run.name), f\"{plate_dir.name}: invalid run dir {run.name}\"\n        assert (run / \"metrics.json\").exists(), f\"{run}: missing metrics.json\"\n\nprint(\"[5] Run directory naming (if any) OK (OK)\")\n\n# ------------------------------------------------------------\n# 6. Ledger presence (not population)\n# ------------------------------------------------------------\n\nexpected_ledgers = {\n    \"plates.parquet\",\n    \"runs.parquet\",\n    \"embeddings.parquet\",\n    \"segments.parquet\",\n}\n\nfound_ledgers = {p.name for p in LEDGER_DIR.iterdir() if p.is_file()}\nassert expected_ledgers.issubset(found_ledgers), (\n    f\"Ledger files missing: {expected_ledgers - found_ledgers}\"\n)\n\nprint(\"[6] Ledger scaffolding present (OK)\")\n\n# ------------------------------------------------------------\n# 7. Summary\n# ------------------------------------------------------------\n\nprint(\"\\n==============================\")\nprint(\"CONTRACT STATUS: ASSERTED\")\nprint(\"==============================\")\nprint(\n    \"\\n\"\n    \"Filesystem, naming, and structural invariants\\n\"\n    \"are intact.\\n\\n\"\n    \"It is now safe to:\\n\"\n    \"- start new runs\\n\"\n    \"- generate embeddings\\n\"\n    \"- perform segmentation\\n\"\n    \"- write derived artifacts\\n\"\n)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "!pip install pillow numpy matplotlib tqdm\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================================\n# CLEANUP: REMOVE BASELINE IMAGE METADATA OUTPUTS\n# ------------------------------------------------------------\n# Deletes ONLY:\n#   - input_image.json\n#\n# Does NOT touch:\n#   - source images\n#   - manifest.json\n#   - source.sha256\n#   - runs/\n#   - viz/\n#   - cache/\n#   - ledgers\n# ============================================================\n\nfrom pathlib import Path\n\nPLATES_STRUCTURED = DATASET_ROOT / \"plates_structured\"\n\nremoved = 0\n\nfor plate_dir in PLATES_STRUCTURED.iterdir():\n    if not plate_dir.is_dir():\n        continue\n\n    target = plate_dir / \"input_image.json\"\n    if target.exists():\n        target.unlink()\n        removed += 1\n\nprint(f\"Cleanup complete.\")\nprint(f\"Removed input_image.json files: {removed}\")\nprint(\"Dataset restored to pre-baseline state.\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================================\n# REPO-WIDE EXPLORATORY (READ-ONLY, CPU-ONLY)\n# ------------------------------------------------------------\n# Purpose:\n#   - Understand structure, scale, and anomalies\n#   - No writes, no heavy image loads\n#   - Header-only inspection where possible\n# ============================================================\n\nimport json\nfrom collections import Counter\nfrom PIL import Image\n\nImage.MAX_IMAGE_PIXELS = None\n\nROOT = DATASET_ROOT\nPLATES_STRUCTURED = ROOT / \"plates_structured\"\nLEDGER_DIR = ROOT / \"ledger\"\nSCHEMA_DIR = ROOT / \"schemas\"\n\nprint(\"\\n==============================\")\nprint(\"REPO EXPLORATORY REPORT\")\nprint(\"==============================\\n\")\n\n# ------------------------------------------------------------\n# 1. Top-level structure\n# ------------------------------------------------------------\n\ntop_dirs = sorted([p.name for p in ROOT.iterdir() if p.is_dir()])\ntop_files = sorted([p.name for p in ROOT.iterdir() if p.is_file()])\n\nprint(\"[1] Top-level directories:\")\nfor d in top_dirs:\n    print(\"  -\", d)\n\nprint(\"\\n[1] Top-level files:\")\nfor f in top_files:\n    print(\"  -\", f)\n\n# ------------------------------------------------------------\n# 2. Plate inventory\n# ------------------------------------------------------------\n\nplate_dirs = sorted(\n    p for p in PLATES_STRUCTURED.iterdir()\n    if p.is_dir() and p.name.startswith(\"plate-\")\n)\n\nprint(f\"\\n[2] Plates found: {len(plate_dirs)}\")\n\nmissing_manifest = []\nmissing_source = []\nrun_counts = []\n\nfor p in plate_dirs:\n    if not (p / \"manifest.json\").exists():\n        missing_manifest.append(p.name)\n\n    src_dir = p / \"source\"\n    if not src_dir.exists():\n        missing_source.append(p.name)\n    else:\n        files = list(src_dir.iterdir())\n        if len(files) != 1:\n            missing_source.append(p.name)\n\n    runs_dir = p / \"runs\"\n    if runs_dir.exists():\n        run_counts.append(len([r for r in runs_dir.iterdir() if r.is_dir()]))\n    else:\n        run_counts.append(0)\n\nprint(\"    Missing manifest.json:\", len(missing_manifest))\nprint(\"    Missing/invalid source:\", len(missing_source))\nprint(\"    Plates with runs:\", sum(1 for c in run_counts if c > 0))\nprint(\"    Total runs:\", sum(run_counts))\n\n# ------------------------------------------------------------\n# 3. Manifest field sampling\n# ------------------------------------------------------------\n\nprint(\"\\n[3] Manifest field coverage (sampled)\")\n\nkey_counter = Counter()\nsampled = 0\n\nfor p in plate_dirs[:50]:\n    try:\n        m = json.loads((p / \"manifest.json\").read_text())\n        key_counter.update(m.keys())\n        sampled += 1\n    except Exception:\n        pass\n\nfor k, v in key_counter.most_common():\n    print(f\"  {k:20s} -> present in {v}/{sampled}\")\n\n# ------------------------------------------------------------\n# 4. Image header inspection (NO full loads)\n# ------------------------------------------------------------\n\nprint(\"\\n[4] Image header stats (source images only)\")\n\nsizes = []\nhuge = []\n\nfor p in plate_dirs:\n    try:\n        src = next((p / \"source\").iterdir())\n        with Image.open(src) as img:\n            w, h = img.size\n        mp = (w * h) / 1_000_000\n        sizes.append(mp)\n        if mp > 90:\n            huge.append((p.name, round(mp, 2)))\n    except Exception:\n        pass\n\nif sizes:\n    print(f\"    Min megapixels: {round(min(sizes), 2)}\")\n    print(f\"    Max megapixels: {round(max(sizes), 2)}\")\n    print(f\"    Mean megapixels: {round(sum(sizes)/len(sizes), 2)}\")\n    print(f\"    Images > 90 MP (PIL warning risk): {len(huge)}\")\n\nfor name, mp in huge[:5]:\n    print(f\"      - {name}: {mp} MP\")\n\n# ------------------------------------------------------------\n# 5. Ledgers & schemas\n# ------------------------------------------------------------\n\nprint(\"\\n[5] Ledger files\")\nif LEDGER_DIR.exists():\n    for p in sorted(LEDGER_DIR.iterdir()):\n        if p.is_file():\n            print(f\"  - {p.name:20s} {round(p.stat().st_size/1024, 1)} KB\")\nelse:\n    print(\"  Ledger directory missing\")\n\nprint(\"\\n[5] Schemas\")\nif SCHEMA_DIR.exists():\n    for p in sorted(SCHEMA_DIR.iterdir()):\n        print(\"  -\", p.name)\nelse:\n    print(\"  Schema directory missing\")\n\n# ------------------------------------------------------------\n# 6. Summary\n# ------------------------------------------------------------\n\nprint(\"\\n==============================\")\nprint(\"SUMMARY\")\nprint(\"==============================\")\nprint(\n    f\"\\n\"\n    f\"Plates                : {len(plate_dirs)}\\n\"\n    f\"Total runs            : {sum(run_counts)}\\n\"\n    f\"Images > 90 MP        : {len(huge)}\\n\"\n    f\"Manifests missing     : {len(missing_manifest)}\\n\"\n    f\"Source issues         : {len(missing_source)}\\n\"\n    f\"Schemas present       : {SCHEMA_DIR.exists()}\\n\"\n    f\"Ledgers present       : {LEDGER_DIR.exists()}\\n\"\n)\n\nprint(\"Exploratory complete. No files written.\")\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}